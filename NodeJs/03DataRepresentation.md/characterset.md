1ï¸âƒ£ What is a character set in a computer?

A computer only understands numbers (0 and 1).
But humans use letters, digits, symbols, emojis, languages, etc.

So a character set is:

A mapping between characters and numbers

Example idea:

A â†’ 65
B â†’ 66
a â†’ 97
0 â†’ 48


Without a character set:

Computer sees numbers

Humans see text

No common language between them âŒ

With a character set:

Computer stores numbers

Software shows correct characters âœ…

ğŸ“Œ In short:
Character set = rulebook that tells which number represents which character

2ï¸âƒ£ Why does ASCII store maximum 128 characters?

ASCII = American Standard Code for Information Interchange

It was created in the 1960s, mainly for:

English language

Teletypes

Early computers

Communication between machines

English doesnâ€™t need:

Accents

Other languages

Emojis ğŸ˜„

So ASCII included:

English letters (Aâ€“Z, aâ€“z)

Digits (0â€“9)

Symbols (@ # $ %)

Control characters (Enter, Tab, Newline)

Total needed characters â‰ˆ 128

Thatâ€™s why:

ASCII range = 0 to 127 â†’ total 128 characters

3ï¸âƒ£ Why ASCII uses 7 bits?

Because of math + hardware limitations of that era.

Binary math:
1 bit  â†’ 2 values
7 bits â†’ 2â· = 128 values


Perfect match:

7 bits = 128 characters

Exactly what ASCII needed

Why not 8 bits?

Early systems were expensive

Saving 1 bit mattered

Data transmission was slower

7 bits was enough for English

Later:

Computers moved to 8-bit bytes

Extended ASCII (0â€“255) appeared

Still messy and inconsistent

ğŸ“Œ So:

ASCII is 7-bit because 2â· = 128 characters and that was sufficient at the time

4ï¸âƒ£ What is Unicode?

ASCII solved English
But the world uses:

Hindi

Punjabi

Chinese

Arabic

Emojis

Symbols

Mathematical signs

ASCII totally fails here âŒ

Unicode came to fix this

Unicode is:

A universal character set that assigns a unique number to every character in every language

Examples:

A      â†’ U+0041
à¤…      â†’ U+0905
à¨•      â†’ U+0A15
ä¸­     â†’ U+4E2D
ğŸ˜€      â†’ U+1F600


Unicode can handle:

All languages

Emojis

Ancient scripts

Math symbols

Important clarification (very important for devs ğŸ‘‡)
Unicode â‰  UTF-8

Unicode = standard
UTF-8 / UTF-16 / UTF-32 = encoding formats

UTF-8:

Variable length (1 to 4 bytes)

Backward compatible with ASCII

Most popular on the web ğŸŒ

Example:

A      â†’ 1 byte
à¤…      â†’ 3 bytes
ğŸ˜€      â†’ 4 bytes


Thatâ€™s why:

Websites

Node.js

React

Databases
mostly use UTF-8

One-line summary (perfect for notes)

Character set: Mapping of characters to numbers

ASCII: 7-bit system â†’ 128 English characters

7 bits: 2â· = 128, hardware-friendly at that time

Unicode: Global standard for all languages and symbols